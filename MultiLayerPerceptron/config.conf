#number of hidden layers
global hidden_layers 	  = 1; 

#max tolerance error to neural network output
global max_error			  = 0.005;

#learning factor should be small
global learning_factor     = 0.1;

#array with number of units(without bias) on each layer going from input layer to output layer
global units_per_layer      = [2, 2, 1];

#value of 0 for incremental and 1 for batch
global method 			  = 0;

#initialize weights with 0  random 1 fanning 2 normalized inputs
global weight_init_method   = 0;

#When init method is random interval would be [-randAbsolut, randAbsolut]
global rand_absolut        = 0.5;

#0 for no momentum, 1 for momentum
global momentum           = 0;

#activation function for layer 0 tanh, 1 exp, 2 linear
global function_type = 0;