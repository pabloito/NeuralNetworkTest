#number of hidden layers
global hidden_layers = 1; 

#max tolerance error to neural network output
global max_error = 0.03;

#learning factor should be small
global learning_rate = 0.03;

#Percentage of sample to analyze
global sample_percentage = 0.8;

#array with number of units(without bias) on each layer going from input layer to output layer
global units_per_layer = [2, 9, 1];

#value of 0 for incremental and 1 for batch
global method = 0;

#initialize weights with 0 random 1 he-et-al
global weight_init_method = 1;

#When init method is random interval would be [-randAbsolut, randAbsolut]
global rand_absolut = 0.5;

#0 for no momentum, (0,1] for momentum
global momentum_alpha = 0; #0.9

#activation function for layer 0 linear, 1 exp, 2 tanh
global function_type = 1;

#1 for adaptive learning, 0 for non-adaptive
global adaptive_learning = 0;

########################################################
#            Adaptative Learning Rate                  #
#                                                      #
#           { +a    if delta_E < 0 in the last k steps #
# delta_n = { -bn   if delta_E > 0                     #
#           { 0     else                               #
#                                                      #
global learning_rate_k = 5;
global learning_rate_a = 0.001;
global learning_rate_b = 0.2;
