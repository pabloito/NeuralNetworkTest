#number of hidden layers
hidden_layers = 2; 

#max tolerance error to neural network output
 max_error = 0.01;

#learning factor should be small
 learning_rate = 0.03;

#array with number of units(without bias) on each layer going from input layer to output layer
 units_per_layer = [2, 9, 9, 1];

#value of 0 for incremental and 1 for batch
 method = 1;

#initialize weights with 0 random 1 he-et-al
 weight_init_method = 1;

#amount of rows per batch
 batch_quantity = 1; 
 
 
#When init method is random interval would be [-randAbsolut, randAbsolut]
 rand_absolut = 0.5;

#0 for no momentum, (0,1] for momentum
 momentum_alpha = 0.9; #0.9

#activation function for layer 0 linear, 1 exp, 2 tanh
 function_type = 2;

#1 for adaptive learning, 0 for non-adaptive
 adaptive_learning = 1;

########################################################
#            Adaptative Learning Rate                  #
#                                                      #
#           { +a    if delta_E < 0 in the last k steps #
# delta_n = { -bn   if delta_E > 0                     #
#           { 0     else                               #
#                                                      #
 learning_rate_k = 5;
 learning_rate_a = 0.001;
 learning_rate_b = 0.2;
